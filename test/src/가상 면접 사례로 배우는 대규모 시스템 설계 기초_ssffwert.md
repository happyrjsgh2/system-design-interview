# 가상 면접 사례로 배우는 대규모 시스템 설계 기초  
### 엘렉스 쉬 지음 | 이병준 옮김  
  
  
# 1장 사용자 수에 따른 규모 확장성  
## 단일서버  
사용자 요청 처리 흐름  
1. 사용자는 도메인 이름(api.mysite.com)을 이용하여 웹사이트에 접속한다.  
이 접속을 위해서는 도메인 이름을 도메인 이름 서비스(Domain Name Service, DNS)에 질의하여 IP 주소로 변환하는 과정이 필요하다.  
2. DNS 조회 결과로 IP 주소가 반환된다. 이 주소는 웹서버의 주소이다.  
3. 해당 IP 주소로 HTTP 요청이 전달된다.  
4. 요청을 받는 웹 서버는 HTML 페이지나 JSON 형태의 응답을 반환한다.  
  
  
## 데이터베이스  
전통적인 관계형 데이터베이스와 비-관계형 데이터베이스가 있다.  
관계형 데이터베이스는 관계형 데이터베이스 관리 시스템(RDBMS)이라고도 부르는데, 가장 유명한 것은 MySQL, 오라클, PostgeSQL 등이 있다.  
  
비 관계형 데이터베이스는 NoSQL이라고도 부른다.  
NoSQL은 다시 네 부류로 나눌 수 있는데, 키-값 저장소, 그래프 저장소, 칼럼 저장소, 그리고 문서 저장소가 있다.  
일반적으로 조인 연산은 지원하지 않는다.  
비 관계형 데이터베이스의 적합한 예  
1. 아주 낮은 응답 지연시간이 요구됨  
2. 다루는 데이터가 비정형이라 관계형 데이터가 아님  
3. 데이터를 직렬화하거나 역직렬화 할 수 있기만 하면 됨  
4. 아주 많은 양의 데이터를 저장할 필요가 있음  
  
  
## 수직적 규모 확장 vs 수평적 규모 확장  
'스케일 업'이라고도 하는 수직적 규모 확장 프로세스는 서버에 고사양 자원(더 좋은 CPU, 더 많은 RAM 등)을 추가하는 행위이다.  
반면 '스케일 아웃'이라고도 하는 수평적 규모 확장 프로세스는 더 많은 서버를 추가하여 성능을 개선하는 행위를 말한다.  
  
서버로 유입되는 트래픽의 양이 적을 때는 수직적 확장이 좋은 선택이다.  
단순한 장점이 있으나, 무한대로 증설할 수 없는 단점이 있고, 장애에 대한 자동복구 방안이나 다중화 방안을 제시하지 않는다.  
  
  
### 로드밸런서  
부하 분산 집합에 속한 웹 서버들에게 트래픽 부하를 고르게 분산하는 역할을 한다.  
사용자는 로드밸런서의 공개 IP주소로 접속한다.  
따라서 웹 서버는 클라이언트의 접속을 직접 처리하지 않는다.  
더 나은 보안을 위해, 서버 간 통신에는 사설 IP주소가 이용된다.  
  
서버 1이 다운되면 모든 트래픽은 서버 2로 전송된다.  
웹사이트로 유입되는 트래픽이 가파르게 증가하면, 웹 서버 계층에 더 많은 서버를 추가하기만 하면 된다.  
  
  
### 데이터베이스 다중화  
많은 데이터베이스 관리 시스템이 다중화를 지원한다.  
보통은 서버 사이에 주-부 관계를 설정하고, 데이터 원본은 주 서버에, 사본은 부 서버에 저장하는 방식이다.  
부 데이터베이스는 읽기 연산만을 지원하고, 그 외에 DML은 주 데이터베이스로만 전달되어야 한다.  
따라서 통상 부 데이터베이스의 수가 더 많다.  
  
  
  
## 캐시  
캐시는 값비싼 연산 결과 또는 자주 참조되는 데이터를 메모리 안에 두고, 뒤이은 요청이 보다 빨리 처리될 수 있도록 하는 저장소이다.  
  
  
### 캐시 계층  
캐시 계층은 데이터가 잠시 보관되는 곳으로 데이터베이스보다 훨씬 빠르다.  
읽기 주도형 캐시 전략이란, 데이터가 캐시에 있으면 캐시에서 데이터를 읽고,  
없으면 데이터베이스에서 해당 데이터를 읽어 캐시에 쓰고나서 웹서버에 데이터를 반환하는 전략이다.  
  
캐시 서버를 이용하는 방법은 간단한데, 대부분의 캐시 서버들이 일반적으로 널리 쓰이는 프로그래밍 언어로 API를 제공하기 때문이다.  
  
  
### 캐시 사용시 유의할 점  
1. 데이터 갱신은 자주 일어나지 않지만 참조는 빈번하게 일어나는 상황에 고려해볼 만하다.  
2. 캐시는 데이터를 비활성 메모리에 두므로, 영속적으로 보관할 데이터를 캐시에 두는 것은 바람직하지 않다.  
3. 만료 정책을 마련해 두는 것은 좋은 습관이다.  
4. 일관성은 데이터 저장소의 원본과 캐시 내의 사본이 같은지 여부다.  
저장소의 원본을 갱신하는 연산과 캐시를 갱신하는 연산이 단일 트랜잭션으로 처리되지 않는 경우, 이 일관성은 깨질 수 있다.  
5. 여러 지역에 걸쳐 캐시 서버를 분산시켜야 한다.  
6. 캐시 메모리를 과할당 하는 방법도 있다.  
7. 데이터 방출 정책에는 LRU(마지막으로 사용된 시점이 가장 오래된 데이터를 내보내는 정책),  
LFU(사용된 빈도가 가장 낮은 데이터를 내보내는 정책),  
FIFO(가장 먼저 캐시에 들어온 데이터를 가장 먼저 내보내는 정책)와 같은 정책 중 경우에 맞게 적용 가능하다.  
  
  
## 콘텐츠 전송 네트워크(CDN)  
CDN은 정적 콘텐츠를 전송하는 데 쓰이는, 지리적으로 분산된 서버의 네트워크이다.  
이미지, 비디오, CSS, JavaScript 파일 등을 캐시할 수 있다.  
  
CDN과 캐시가 추가된 설계로 변화될 수 있는 부분은  
1. 정적 콘텐츠는 더 이상 웹 서버를 통해 서비스하지 않으며, CDN을 통해 제공하여 더 나은 성능을 보장한다.  
2. 캐시가 데이터베이스 부하를 줄여준다.  
  
  
## 무상태(stateless) 웹 계층  
웹 계층을 수평적으로 확장하는 방법을 고민해 볼 수 있다.  
이를 위해서는 상태 정보(사용자 세션 데이터와 같은)를 웹 계층에서 제거하여야 한다.  
바람직한 전략은 상태 정보를 관계형 데이터베이스나 NoSQL 같은 지속성 저장소에 보관하고,  
필요할 때 가져오도록 하는 것이다.  
이렇게 구성된 웹 계층을 무상태 웹 계층이라 부른다.  
  
  
### 무상태 아키텍처  
세션 데이터를 웹 계층에서 분리하고 지속성 데이터 보관소에 저장하도록 만들 수 있다.  
이 공유 저장소는 관계형 데이터베이스일 수도 있고, Memcached/Redis 같은 캐시 시스템일 수도 있으며,  
NoSQL일 수도 있다.  
  
  
## 데이터 센터  
두 개의 데이터 센터를 이용하는 사례를 예를 들면,  
장애가 없는 상황에서 사용자는 가장 가까운 데이터 센터로 안내되는데, 이 절차를 지리적 라우팅이라고 부른다.  
지리적 라우팅에서의 geoDNS는 사용자의 위치에 따라 도메인 이름을 어떤 IP로 변환할지 결정할 수 있도록 해 주는 DNS 서비스다.  
  
시스템을 더 큰 규모로 확장하기 위해서는 시스템의 컴포넌트를 분리하여, 각기 독립적으로 확장될 수 있도록 하여야 한다.  
  
  
## 메시지 큐  
메시지 큐는 메시지의 무손실(즉, 메시지 큐에 일단 보관된 메시지는 소비자가 꺼낼 때까지 안전히 보관된다는 특성)을 보장하는, 비동기 통신을 지원하는 컴포넌트다.  
메시지 큐를 이용하면 서비스 또는 서버 간 결합이 느슨해져서, 규모 확장성이 보장되어야 하는 안정적 애플리케이션을 구성하기 좋다.  
  
  
## 로그, 메트릭 그리고 자동화  
## 데이터베이스의 규모 확장  
## 백만 사용자, 그리고 그 이상  
시스템 규모를 확장하는 것은 지속적이고 반복적인 과정이다.  
예를 들어, 시스템을 최적화하고 더 작은 단위의 서비스로 분할해야 할 수도 있다.  
  
시스템 규모 확장을 위해 살펴본 기법  
1. 웹 계층은 무상태 계층으로  
2. 모든 계층에 다중화 도입  
3. 가능한 한 많은 데이터를 캐시할 것  
4. 여러 데이터 센터를 지원할 것  
5. 정적 콘텐츠는 CDN을 통해 서비스할 것  
6. 데이터 계층은 샤딩을 통해 그 규모를 확장할 것  
7. 각 계층은 독립적 서비스로 분할할 것  
8. 시스템을 지속적으로 모니터링하고, 자동화 도구들을 활용할 것  
  
  
  
# 2장 개략적인 규모 추정  
## 2의 제곱수  
최소 단위는 1바이트이고, 8비트이다.  
ASCII 문자 하나가 차지하는 메모리 크기가 1바이트이다.  
  
  
## 모든 프로그래머가 알아야 하는 응답지연 값  
수치들을 분석하면 다음과 같은 결론이 나온다.  
1. 메모리는 빠르지만 디스크는 아직도 느리다.  
2. 디스크 탐색(seek)은 가능한 한 피하라.  
3. 단순한 압축 알고리즘은 빠르다.  
4. 데이터를 인터넷으로 전송하기 전에 가능하면 압축하라.  
5. 데이터 센터는 보통 여러 지역(region)에 분산되어 있고, 센터들 간에 데이터를 주고받는 데는 시간이 걸린다.  
  
  
## 가용성에 관계된 수치들  
고가용성은 시스템이 오랜 시간 동안 지속적으로 중단 없이 운영될 수 있는 능력을 지칭하는 용어다.  
고가용성을 표현하는 값은 퍼센트로 표현하는데, 100%는 시스템이 단 한 번도 중단된 적이 없었음을 의미한다.  
대부분의 서비스는 99%에서 100% 사이의 값을 갖는다.  
  
  
## 예제: 트위터 QPS와 저장소 요구량 추정  
## 팁  
개략적인 규모 추정과 관계된 면접에서 가장 중요한 것은 문제를 풀어 나가는 절차다.  
근사치를 활용한 계산을 하고, 가정들은 적어 두고, 단위를 붙이며,  
QPS, 캐시 요구량, 서버 수 등을 추정하는 계산 연습을 해 두자.  
  
  
  
# 3장 시스템 설계 면접 공략법  
시스템 설계 면접은 두 명의 동료가 모호한 문제를 풀기 위해 협력하여 그 해결책을 찾아내는 과정에 대한 시뮬레이션이다.  
이 면접은 설계 기술을 시연하는 자리이고, 설계 과정에서 내린 결정들에 대한 방어 능력을 보이는 자리이며,  
면접관의 피드백을 건설적인 방식으로 처리할 자질이 있음을 보이는 자리이다.  
  
  
## 효과적 면접을 위한 4단계 접근법  
### 1단계 문제 이해 및 설계 범위 확정  
바로 답부터 들이밀지 말고, 속도를 늦춰 깊이 생각하고 질문하여 요구사항과 가정들을 분명히 한다.  
  
  
### 2단계 개략적인 설계안 제시 및 동의 구하기  
개략적인 설계안을 제시하고 면접관의 동의를 얻는다. 이 과정은 면접관과 협력하여 진행하면 좋다.  
화이트보드나 종이에 핵심 컴포넌트를 포함하는 다이어그램을 그리고,  
제약사항들을 만족하는지 개략적으로 계산해본다.  
  
  
### 3단계 상세 설계  
설계 대상 컴포넌트 사이의 우선순위를 정한다.  
  
  
### 4단계 마무리  
면접관은 후속 질문을 던질수도 있고, 스슬 추가 논의를 진행하도록 할 수도 있다.  
1. 시스템 병목구간, 혹은 좀 더 개선 가능한 지점을 찾아내라 주문할 수 있다.  
2. 만든 설계를 한번 다시 요약해주는 것도 도움이 될 수 있다.  
3. 오류가 발생하면 무슨 일이 생기는지 짚어본다.  
4. 운영 이슈도 논할 가치가 충분하다.(메트릭은 어떻게 수집하고 모니터링 할 것인가? 로그는? 시스템은 어떻게 배포해 나갈 것인가?)  
5. 규모 확장 요구에 어떻게 대처할 것인가  
6. 다루지 못했던 세부적 개선사항들  
  
  
### 시간 배분  
1단계 - 문제 이해 및 설계 범위 확정: 3분에서 10분  
2단계 - 개략적 설계안 제시 및 동의 구하기: 10분에서 15분  
3단계 - 상세 설명: 10분에서 25분  
4단계 - 마무리: 3분에서 5분  
  
  
  
# 4장 처리율 제한 장치의 설계  
네트워크 시스템에서 처리율 제한 장치(rate limiter)는 클라이언트 또는 서비스가 보내는 트래픽의 처리율(rate)를 제어하기 위한 장치다.  
HTTP를 예를 들면 이 장치는 특정 기간 내에 전송되는 클라리언트의 요청 횟수를 제한한다.  
  
### API에 처리율 제한 장치를 두면 좋은 점  
1. DOS(Denial of Service) 공격에 의한 자원 고갈을 방지할 수 있다.  
(DOS는 한 대의 PC만으로도 수행할 수 있지만, DDOS는 분산된 여러 PC를 동시에 이용하여 서버의 가동을 방해하는 측면에서 차이가 있다.)  
2. 서버를 많이 두지 않아도 되기 때문에 비용을 절감한다.  
3. 서버 과부하를 막는다.  
  
  
## 1단계 문제 이해 및 설계 범위 확정  
### 요구사항  
1. 설정된 처리율을 초과하는 요청은 정확하게 제한한다.  
2. 낮은 응답시간: 이 처리울 제한 장치는 HTTP 응답시간에 나쁜 영향을 주어서는 곤란한다.  
3. 가능한 한 적은 메모리를 써야 한다.  
4. 분산형 처리율 제한: 하나의 처리율 제한 장치를 여러 서버나 프로세스에서 공유할 수 있어야 한다.  
5. 예외 처리: 요청이 제한되었을 때는 그 사실을 사용자에게 분명하게 보여주어야 한다.  
6. 높은 결함 감내성: 제한 장치에 장애가 생기더라도 전체 시스템에 영향을 주어서는 안된다.  
  
  
  
## 2단계 개략적 설계안 제시 및 동의 구하기  
기본적으로는 클라이언트-서버 통신 모델을 사용.  
  
### 처리율 제한 장치는 어디에 둘 것인가?  
클라이언트 측에 두는 것 보다는, 서버 측에 두거나 처리율 제한 미들웨어를 만들어 통제한다.  
폭 넓게 채택된 기술인 클라우드 마이크로서비스의 경우, 처리율 제한 장치는 보통 API 게이트웨이라 불리는 컴포넌트에 구현된다.  
(API 게이트웨이는 처리율 제한, SSL 종단, 사용자 인증, IP 허용목록 관리 등을 지원하는 완전 위탁관리형 서비스로,  
즉 클라우드 업체가 유지 보수를 담당하는 서비스이다.)  
  
  
### 처리율 제한 알고리즘  
1. 토큰 버킷  
2. 누출 버킷  
3. 고정 윈도 카운터  
4. 이동 윈도 로그  
5. 이동 윈도 카운터  
  
  
### 1. 토큰 버킷 알고리즘  
#### 동작원리  
토큰 버킷은 지정된 용량을 갖는 컨테이너이다.  
이 버킷에는 사전 설정된 양의 토큰이 주기적으로 채워진다.  
토큰이 꽉 찬 버킷에는 더 이상의 토큰은 추가되지 않는다.  
  
이 토큰 버킷 알고리즘은 2개 인자를 받는다.  
1. 버킷 크기: 버킷에 담을 수 있는 토큰의 최대 개수  
(통상적으로, API 엔드포인트마다 별도의 버킷을 둔다.)  
2. 토큰 공급률: 초당 몇 개의 토큰이 버킷에 공급되는가  
  
  
#### 장점  
1. 구현이 쉽다.  
2. 메모리 사용 측면에서도 효율적이다.  
3. 짧은 시간에 집중되는 트래픽도 처리 가능하다.  
(버킷에 남은 토큰이 있기만 하면 요청은 시스템에 전달된다.)  
  
#### 단점  
1. 이 알고리즘은 버킷 크기와 토큰 공급률이라는 두 개 인자를 가지고 있는데,  
이 값을 적절하게 튜닝하는 것은 까다로운 일이 될 것이다.  
  
  
### 2. 누출 버킷 알고리즘  
#### 동작원리  
토큰 버킷 알고리즘과 비슷하지만, 처리율이 고정되어 있다.(고정 속도로 처리)  
보통 FIFO 큐로 구현하여, 지정된 시간마다 큐에서 요청을 꺼내어 처리한다.  
  
#### 2개의 인자를 사용  
1. 버킷 크기: 큐 사이즈와 같은 값으로, 큐에는 처리될 항목들이 보관된다.  
2. 처리율: 지정된 시간당 몇 개의 항목을 처리할지 지정하는 값이다. 보통 초 단위로 표현한다.  
  
  
#### 장점  
1. 큐의 크기가 제한되어 있어, 메모리 사용량 측면에서 효율적이다.  
2. 고정된 처리율을 갖고 있기 때문에, 안정적 출력이 필요한 경우에 적합하다.  
  
#### 단점  
1. 단시간에 많은 트래픽이 몰리는 경우 큐에는 오래된 요청들이 쌓이게 되고,  
그 요청들을 제때 처리 못하면 최신 요청들은 버려지게 된다.  
2. 두 개 인자를 올바르게 튜닝하기가 까다로울 수 있다.  
  
  
### 3. 고정 윈도 카운터 알고리즘  
#### 동작 원리  
1. 타임라인을 고정된 간격의 윈도로 나누고, 각 윈도마다 카운터를 붙인다.  
2. 요청이 접수될 때마다 이 카운터의 값은 1씩 증가한다.  
3. 이 카운터의 값이 사전에 설정된 임계치에 도달하면, 새로운 요청은 새 윈도가 열릴 때까지 버려진다.  
  
#### 이슈  
윈도의 경계 부근에 순간적으로 많은 트래픽이 집중될 경우 윈도에 할당된 양보다 더 많은 요청이(허용 한도의 2배까지) 처리 될 수 있다.  
  
  
#### 장점  
1. 메모리 효율이 좋다.  
2. 이해하기 쉽다.  
3. 윈도가 닫히는 시점에 카운터를 초기화하는 방식은 특정한 트래픽 패턴을 처리하기에 적합하다.  
  
#### 단점  
1. 윈도 경계 부근에서 일시적으로 많은 트래픽이 몰려드는 경우, 기대했던 시스템의 처리 한도보다 많은 양의 요청을 처리하게 된다.  
  
  
### 4. 이동 윈도 로깅 알고리즘  
#### 동작 원리  
고정 윈도 카운터 알고리즘의 단점을 해결한다.  
1. 요청의 타임스탬프를 추적한다.  
타임스탬프 데이터는 보통 레디스의 정렬 집합 같은 캐시에 보관한다.  
2. 새 요청이 오면 타임스탬프는 제거한다. 만료된 타임스탬프는 그 값이 현재 윈도의 시작 시점보다 오래된 타임스탬프를 말한다.  
3. 새 요청의 타임스탬프를 로그에 추가한다.  
(보통 로그에 보관되는 값은 리눅스 타임스탬프이다.)  
4. 로그의 크기가 허용치보다 같거나 작으면, 요청을 시스템에 전달한다. 그렇지 않은 경우에는 처리를 거부한다.  
  
  
#### 장점  
1. 이 알고리즘이 구현하는 처리율 제한 메커니즘은 아주 정교하다.  
(어느 순간의 윈도를 보더라도, 허용되는 요청의 개수는 시스템의 처리율 한도를 넘지 않는다.)  
  
#### 단점  
1. 이 알고리즘은 다량의 메모리를 사용하는데, 거부된 요청의 타임스탬프도 보관하기 때문이다.  
  
  
### 5. 이동 윈도 카운터 알고리즘  
고정윈도 카운터 알고리즘과 이동 윈도 로깅 알고리즘을 결합한 것이다.  

#### 접근법1  
처리율 제한 장치의 한도가 분당 7개의 요청으로 설정되어 있을 때,  
이전 1분동안 5개의 요청이, 그리고 현재 1분동안 3개의 요청이 왔고,  
새 요청이 도착하면  현재 윈도에 몇 개의 요청이 온 것으로 보고 처리해야 하는가?  
-> 현재 1분간의 요청 수(3) + 직전 1분간의 요청수(5) * 이동 윈도와 직전 1분이 겹치는 비율(70%) = 6.5개(반올림 혹은 내림하여 적용)  
  
  
#### 장점  
1. 이전 시간대의 평균 처리율에 따라 현재 윈도의 상태를 계산하므로 짧은 시간에 몰리는 트래픽에도 잘 대응한다.  
2. 메모리 효율이 좋다.  
  
#### 단점  
1. 직전 시간대에 도착한 요청이 균등하게 분포되어 있다고 가정한 상태에서 추정치를 계산하기 때문에 다소 느슨하다.  
  
  
### 개략적인 아키텍처  
카운터를 보관하는 곳은 메모리상에서 동작하는 캐시가 바람직한데, 빠른데다 시간에 기반한 만료 정책을 지원한다.  
일례로 레디스는 처리율 제한 장치를 구현할 때 자주 사용되는 메모리 저장 장치로서, INCFR과 EXPIRE의 두 가지 명령어를 지원한다.  
1. INCR: 메모리에 저장된 카운터의 값을 1만큼 증가시킨다.  
2. EXPIRE: 카운터에 타임아웃 값을 설정한다. 설정된 시간이 지나면 카운터는 자동으로 삭제된다.  
  
  
  
## 3단계 상세 설계  
### 처리율 제한 규칙  
리프트는 처리율 제한에 오픈 소스를 사용하고 있다.  
   
### 처리율 한도 초과 트래픽의 처리  
클라이언트는 자기 요청이 처리율 제한에 걸리는지를 HTTP 응답 헤더를 통해 알 수 있다.  
다음의 HTTP 헤더를 클라이언트에게 보낸다.  
1. X-Ratelimit-Remaining: 윈도 내에 남은 처리 가능 요청의 수.  
2. X-RateLimit-Limit: 매 윈도마다 클라이언트가 전송할 수 있는 요청의 수.  
3. X-RateLimit-Retry-After: 한도 제한에 걸리지 않으려면 몇 초 뒤에 요청을 다시 보내야 하는지 알림.  
(사용자가 너무 많은 요청을 보내면 429 too many requests 오류를 X-Ratelimit-Retry-After 헤더와 함께 반환하도록 한다.)  
  
  
### 상세 설계  
1. 처리율 제한 규칙은 디스크에 보관한다. 작업 프로세스는 수시로 규칙을 디스크에서 읽어 캐시에 저장한다.  
2. 클라이언트가 요청을 서버에 보내면 요청은 먼저 처리율 제한 미들웨어데 도달한다.  
3. 처리율 제한 미들웨어는 제한 규칙을 캐시에서 가져온다.  
아울러 카운터 및 마지막 요청의 타임스탬프를 레디스 캐시에서 가져온다.  
가져온 값들에 근거하여 해당 미들웨어는 결정을 내린다.  
  
3-1. 해당 요청이 처리율 제한에 걸리지 않은 경우에는 API 서버로 보낸다.  
3-2. 해당 요청이 처리율 제한에 걸렸다면 429 too many requests 에러를 클라이언트에 보낸다.  
(해당 요청은 그대로 버릴 수도 있고 메시지 큐에 보관할 수도 있다.)  
  
  
### 분산 환경에서의 처리율 제한 장치의 구현  
두가지 어려운 문제가 있다.  
1. 경쟁 조건 문제를 해결하는 가장 널리 알려진 해결책은 락이다.  
하지만 락은 시스템의 성능을 상당히 떨어뜨린다는 문제가 있다.  
해결책은 루아 스크립트 혹은 정렬 집합이라 불리는 레디스 자료구조를 쓰는 것이다.  
  
2. 동기화 이슈는 고정 세션을 활용하여 같은 클라이언트로부터의 요청은 항상 같은 처리율 제한 장치로 보낼 수 있도록 하여 해결할 수 있다.  
규모면에서 확장 가능하지 않고 유연하지도 않기 때문에,  
레디스와 같은 중앙 집중형 데이터 저장소를 쓰는 것이 더 나은 해결책이다.  
  
  
  
# 5장 안정 해시 설계  
수평적 규모 확장성을 달성하기 위해서는 요청 또는 데이터를 서버에 균등하게 나누는 것이 중요하다.  
안정 해시는 이 목표를 달성하기 위해 보편적으로 사용하는 기술이다.  
  
  
## 해시 키 재배치(rehash) 문제  
N개의 캐시 서버가 있을 때, 이 서버들에 부하를 균등하게 나누는 보편적 방법은 아래의 해시 함수를 사용하는 것이다.  
serverIndex = hash(key) % N  
1번 서버에 장애가 발생한다면, 보관되어 있는 키 뿐만 아닌 대부분의 키가 재분배 된다.  
#### 이해 안되는 문장 : (p.79)1번 서버가 죽으면 대부분 캐시 클라이언트가 데이터가 없는 엉뚱한 서버에 접속하게 된다는 뜻이다.  
안정 해시는 이 문제를 효과적으로 해결하는 기술이다.  
  
  
## 안정 해시  
안정 해시는 해시 테이블 크기가 조정될 때 평균적으로 오직 k/n개의 키만 재배치하는 해시 기술이다.  
여기서 k는 키의 개수이고, n은 슬롯의 개수다.  
이와는 달리 대부분의 전통적 해시 테이블은 슬롯의 수가 바뀌면 거의 대부분 키를 재배치한다.  
  
  
### 기본 구현법의 두 가지 문제  
안정 해시 알고리즘의 기본 절차는 다음과 같다.  
1. 서버와 키를 균등 분포 해시 함수를 사용해 해시 링에 배치한다.  
2. 키의 위치에서 링을 시계 방향으로 탐색하다 만나는 최초의 서버가 키가 저장될 서버다.  

첫번째 문제는 서버가 추가되거나 삭제되는 상황을 감안하면 파티션의 크기를 균등하게 유지하는 게 불가능하다.  
(파티션은 인접한 서버 사이의 해시 공간이다.)  
어떤 서버는 굉장히 큰 해시 공간을 할당 받는 상황이 가능해진다.  
  
두번째 문제는 키의 균등 분포를 달성하기가 어렵다.  
  
이 문제를 해결하기 위해 제안된 기법이 가상 노드 또는 복제라 불리는 기법이다.  
  
  
## 마치며  
안정 해시의 이점은 다음과 같다.  
1. 서버가 추가되거나 삭제될 때 재배치되는 키의 수가 최소화된다.  
2. 데이터가 보다 균등하게 분포하게 되므로, 수평적 규모 확장성을 달성하기 쉽다.  
3. 핫스팟 키 문제를 줄인다.(특정 샤드에 대한 접근이 지나치게 빈번하면 서버 과부하 문제가 생길 수 있다.)  
  
### 널리 쓰이는 유명한 예  
1. 디스코드 채팅 어플리케이션  
  
  
끝  